\section{Experiment Result}

\begin{table*}[!t]
\centering
\caption{MAE of Estimated Attitude}\label{tab:MAE_of_Error}
\begin{tabular}{|cl|rr|rr|r|}
\hline
\rowcolor[HTML]{C0C0C0} 
\multicolumn{2}{|c|}{\cellcolor[HTML]{C0C0C0}}                                                                                    & \multicolumn{2}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}Inference in \\ Training Environment\end{tabular}}                                                                                                    & \multicolumn{2}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}Inference in \\ Unknown Environment\end{tabular}}                                                                                                     & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}}                                                                                   \\ \cline{3-6}
\rowcolor[HTML]{C0C0C0} 
\multicolumn{2}{|c|}{\multirow{-2}{*}{\cellcolor[HTML]{C0C0C0}Method Name}}                                                       & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}MAE of\\ Roll {[}deg{]}\end{tabular}} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}MAE of\\ Pitch {[}deg{]}\end{tabular}} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}MAE of\\ Roll {[}deg{]}\end{tabular}} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}MAE of\\ Pitch {[}deg{]}\end{tabular}} & \multicolumn{1}{c|}{\multirow{-2}{*}{\cellcolor[HTML]{C0C0C0}\begin{tabular}[c]{@{}c@{}}Inference\\ Time {[}s{]}\end{tabular}}} \\ \hline
\multicolumn{1}{|c|}{}                                                                               & ResNet18                   & \multicolumn{1}{r|}{1.6887}                                                                                  & 1.5555                                                                                                        & \multicolumn{1}{r|}{4.5271}                                                                                  & 9.0285                                                                                                        & 0.020                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                                                               & ResNet34                   & \multicolumn{1}{r|}{1.7674}                                                                                  & 1.8037                                                                                                        & \multicolumn{1}{r|}{4.0867}                                                                                  & 8.3678                                                                                                        & 0.025                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                                                               & ResNet50                   & \multicolumn{1}{r|}{\textbf{1.5245}}                                                                         & \textbf{1.5183}                                                                                               & \multicolumn{1}{r|}{\textbf{3.5384}}                                                                         & \textbf{7.8504}                                                                                               & 0.027                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                                                               & ResNet101                  & \multicolumn{1}{r|}{2.2452}                                                                                  & 1.9573                                                                                                        & \multicolumn{1}{r|}{4.3105}                                                                                  & 8.0860                                                                                                        & 0.036                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{\multirow{-5}{*}{\begin{tabular}[c]{@{}c@{}}Proposed\\ Method\end{tabular}}}    & ResNet152                  & \multicolumn{1}{r|}{1.6938}                                                                                  & 1.9545                                                                                                        & \multicolumn{1}{r|}{3.8817}                                                                                  & 9.3533                                                                                                        & 0.050                                                                                                                           \\ \hline
\multicolumn{1}{|c|}{}                                                                               & Kawai's Method             & \multicolumn{1}{r|}{2.2345}                                                                                  & 2.2633                                                                                                        & \multicolumn{1}{r|}{4.5705}                                                                                  & 12.6040                                                                                                       & 0.010                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{}                                                                               & Ozaki's Method(MLE)        & \multicolumn{1}{r|}{11.7984}                                                                                 & 12.5593                                                                                                       & \multicolumn{1}{r|}{14.4135}                                                                                 & 15.3828                                                                                                       & 0.005                                                                                                                           \\ \cline{2-7} 
\multicolumn{1}{|c|}{\multirow{-3}{*}{\begin{tabular}[c]{@{}c@{}}Camera \\ Image Only\end{tabular}}} & Ozaki's Method(Regression) & \multicolumn{1}{r|}{9.5726}                                                                                  & 7.6709                                                                                                        & \multicolumn{1}{r|}{9.2231}                                                                                  & 14.8570                                                                                                       & 0.005                                                                                                                           \\ \hline
\multicolumn{1}{|c|}{W/O SA-Gate}                                                                    & ResNet50                   & \multicolumn{1}{r|}{1.9692}                                                                                  & 1.7023                                                                                                        & \multicolumn{1}{r|}{4.5331}                                                                                  & 7.3232                                                                                                        & 0.029                                                                                                                           \\ \hline
\end{tabular}
\end{table*}
\subsection{Inference in Known and Unknown Environment}\label{sec:result}
To verify the performance of the network, inferences were tested under the same environment as the training data and the environment of the findings, respectively. The generation of the small windows described in Sec.\ref{sec:random_window} was set up to generate 15 windows. The inference time in the table showing the experimental results is the inference time per window. The number of windows was set to 15 in this experiment in consideration of the balance between estimation time and accuracy.

%ネットワークの性能を確かめるために、訓練データと同じ環境と所見の環境のもとでそれぞれ推論の試験を行った。実験の結果を表AAAAAに示す。表AAAAの中にあるMAEとは、数多くの枚数があるテストデータ中で、一枚一枚推論の試験をしていく中で、真の値と推論の値の誤差を加算して最終的に平均値として算出した値である。AAAAA節で述べた小さい窓の生成は15枚を生成するように設定した。実験結果を示す表にある推論時間は窓1枚あたりの推論時間である。窓の枚数を増やすことでattitude estimationの精度を向上させることが可能であるがそれに合わせて推定時間は増大する、推定時間と精度のバランスを考慮して本実験では窓の枚数を15枚と設定した。


The results of the experiment are shown in Tab.\ref{tab:MAE_of_Error}. The MAE in Tab.\ref{tab:MAE_of_Error} is the value calculated by adding up the errors between the true value and the estimated value in the course of testing the inference for each piece of test data, of which there are numerous pieces, and finally calculating the average value. The inference test results show that the proposed method, which uses the camera image and the depth image as two inputs, has the best inference accuracy. Among the proposed methods, the smallest error value was obtained when ResNet50 was set as the feature extractor. In an unknown environment, all conventional methods using only the camera image have low accuracy in attitude estimation, but the proposed method using both the camera image and the depth image as inputs has better accuracy than conventional methods. However, the proposed method, which uses both the camera image and the depth image as inputs, shows better accuracy than the conventional methods. However, the proposed method, which uses both camera and depth images as inputs, showed better accuracy than the conventional methods. However, the accuracy of these attitude estimation methods is still low considering that they are used on a robot such as the one shown in Fig.\ref{fig:CCV}. To investigate the effect of the SA-Gate, training and inference tests were conducted on the network of the proposed method without the SA-Gate, and ResNet50, which showed the best accuracy in the aforementioned tests, was used as the feature extractor. The results showed that the network without SA-Gate was less accurate than the network with SA-Gate in all values except for the pitch in an unknown environment.

%推論テストの結果、カメラ画像とdepth imageの2つをinputとする提案手法が最も良い推論精度を発揮した。提案手法の中でも、ResNet50をfeature extractorとして設定した時の誤差が最も小さい値となった。unknown environmentにおいて、camera imageのみを用いる従来手法はすべて低いattitude estimation accuracyであったが、camera imageとdepth imageの2つをinputとする提案手法は従来手法より優れた精度を発揮した。しかし、これらのattitude estimation accuracyは図AAAAのようなロボットに搭載することを考えると依然低いaccuracyであった。

%SA-Gateの効果を調べるため、提案手法のネットワークからSA-Gateを抜いたものを用意して学習と推論試験を行った。feature extractorには先程述べた試験において最も優れた精度であったResNet50を用いた。試験の結果、SA-Gate抜きのネットワークはunknown environmentにおけるpitchを除いて全ての値においてSA-Gate有りより精度が低かった。

\subsection{Consideration}\label{sec:consideration}
This method demonstrated the best accuracy in the attitude estimation task in an unknown environment. However, even with this method, many issues remain in practical use. One of the possible reasons for the improvement in accuracy compared to the conventional method is the introduction of SA-Gate, which obtains a feature map by aligning the information obtained from the camera image and the depth image while mutually interfering with each other. The high-quality feature map obtained by this method is considered to have contributed to the improvement of the accuracy of the attitude estimation in unknown environments.

%本手法はunknown environmentにおけるattitude estimation taskにおいて最も優れた精度を発揮した。しかし、それを持ってしても実用面では多くの課題が残る結果となってしまった。従来手法と比較してaccuracyが向上した要因として考えられるのがSA-Gateの導入である。SA-Gateはcamera imageとdepth imageから得られる情報を相互に干渉させながらalignさせてfeature mapを入手する。この手法によって得られる質の高いfeature mapがunknown environmentにおけるattitude estimation accuracyの向上に寄与したと考えられる。

In conventional methods, when a network has data with different modality (e.g., camera image and depth image) as inputs, it is common to concatenate the resulting feature maps\cite{ozaki_robosym}\cite{SAGATE}\cite{RGBD_1}\cite{RGBD_2}. While such methods, including the proposed method, can improve accuracy compared to the case of using only camera images, the structure of the network becomes more complex, increasing computational cost. However, the accuracy did not improve that much in response to the increased processing burden, and this has become a problem in the practical application of networks with cross-modality information as input. We believe that the method using attention in this method\cite{google_LiDAR_camera} may be effective for such tasks that require multiple types of data as input. It is also pointed out that a decision tree has better classification ability than a neural network in the problem of tabular data classification\cite{DL_isnot}. The proposed method, which uses two types of data as inputs and a classification-type output layer, be a good match for such a method.

%従来までの手法では、camera imageとdepth imageなど異なるmodalityを持つデータをinputとするネットワークでは得られたfeature mapをconcatするやり方が一般であった。提案手法を含めて、このような方法はcamera imageのみの場合と比べて精度を向上させることができる半面、ネットワークの構造は複雑になりcomputational costの増大を招いた。しかし、そのような処理負担の増大に対して精度の向上はそこまで多くなく、cross modalityな情報をinputとするネットワークを実用化する際の問題点となってしまった。


In the unknown environment, the accuracy of pitch estimation was lower than that of roll estimation. Although this method estimates the attitude based on the scenery in the image, the nature of the changes that appear in the image is different when the roll value is changed and when the pitch value is changed. 
Taking the image shown in Fig.\ref{fig:known_env_image} as an example, changing the roll will greatly change the way house and window appear in the image, such as by changing the tilt angle. However, the pitch does not change the tilt, but rather the range of the landscape in the image; in the case of Fig.\ref{fig:known_env_image}, when the angle of the pitch is closer to 0 degrees, the window is more likely to appear in the center of the image, and this also happens when the height of the camera is increased. Unlike roll, pitch was not a sole factor in determining the appearance of the landscape image, which may have been the result of poor pitch accuracy. This suggests that the pitch estimation accuracy was low in the unknown environment, and at the same time, when the network made the attitude estimation, it was based on the reflection of objects that were built vertically to the ground, such as people, furniture, and buildings. The network without SA-Gate had lower accuracy in pitch estimation under unknown environment than the network with SA-Gate, but this may be due to the fact that the network could not fully learn the change of scenery caused by pitch changes even with SA-Gate.

%unknown environmentにおいて、pitchの推定精度はrollでの精度よりも低い値となった。本手法は画像に映る風景をもとにattitudeを推定しているが、rollの値が変わった場合とpitchの値が変わった場合では画像に現れる変化の性質が異なる。Fig.AAAのような画像を例にとると、rollを変更した場合は人やテーブルの傾き角度が変わるなど映り方が大きく変わる。しかし、pitchの場合はこのような傾き方の変更ではなく画像に映る風景の範囲が変わる。pitchの角度を0度に近づけたとき、窓は画像の中央に映りやすくなるが、これはカメラの高さを高くしても同様のことが起きる。rollと異なり、pitchが風景画像の映り方を決める決定的な要素にならなかったのがpitchの精度が悪かった結果であると考えられる。このことからunknown environmentにおいてpitchの推定精度が低かったと考えられ、同時にネットワークがattitude estimationをする際は人や家具、建物など、地面に対して鉛直に建てられている物体の映り方を参考にしていると考えられる。SA-Gateなしのネットワークの方が, ありのものと比べてunknown環境下でのpitch推定精度が低かったが、これはSA-Gateを用いてもネットワークがpitchの変化による風景の変化を学習しきれなかったことが原因と考えられる.